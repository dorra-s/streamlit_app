{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LogProblem=pd.read_csv(r'/home/dorra/LogProblemP.csv')\n",
    "df_InfoUser=pd.read_csv(r'/home/dorra/InfoUserP.csv')\n",
    "df_InfoContent=pd.read_csv(r'/home/dorra/InfoContentP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'gender', 'points', 'badges_cnt', 'first_login_date_TW',\n",
       "       'user_grade', 'user_city', 'has_teacher_cnt', 'is_self_coach',\n",
       "       'has_student_cnt', 'belongs_to_class_cnt', 'has_class_cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LogProblem.columns\n",
    "df_InfoContent.columns\n",
    "df_InfoUser.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGING THE THREE FEATURES INTO LOGPROBLEM FILE : 'has_teacher_cnt', 'points', 'total_sec_taken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LogProblem = df_LogProblem.merge(df_InfoUser[['uuid', 'has_teacher_cnt', 'points']], on='uuid', how='left')\n",
    "#df_LogProblem = df_LogProblem.merge(df_InfoContent[['ucid', 'difficulty']], on='ucid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_LogProblem = pd.get_dummies(df_LogProblem, columns=['difficulty'], prefix='difficulty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING 'AAA' TO LOGPROBLEM FILE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "student_grouped = df_LogProblem.groupby('uuid').agg({\n",
    "    'is_correct': 'sum',\n",
    "    'total_attempt_cnt': 'sum',\n",
    "    'has_teacher_cnt': 'max',   \n",
    "    'points': 'sum',\n",
    "    #'difficulty_easy': 'max',  # One-hot encoding for difficulty\n",
    "    #'difficulty_normal': 'max',\n",
    "    #'difficulty_hard': 'max'\n",
    "})\n",
    "student_grouped['AAA'] = student_grouped['is_correct'] / student_grouped['total_attempt_cnt']\n",
    "\n",
    "student_grouped.reset_index(inplace=True)\n",
    "\n",
    "df_LogProblem = df_LogProblem.merge(student_grouped[['uuid', 'AAA']], on='uuid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = df_LogProblem[['total_sec_taken','has_teacher_cnt','points']].values\n",
    "y = df_LogProblem['AAA'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_indices = ~np.isnan(y)\n",
    "x = x[non_nan_indices]\n",
    "y = y[non_nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "def model(x, y, learning_rate, iterations, batch_size):\n",
    "    m, n = x.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        # Shuffle and split the data into mini-batches\n",
    "        indices = np.arange(m)\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, m, batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            x_batch = x[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            y_batch = y_batch.reshape(-1, 1)\n",
    "\n",
    "            gradient_threshold = 1.0\n",
    "\n",
    "            # Compute the gradient and update theta for this mini-batch\n",
    "            y_pred = np.dot(x_batch, theta)\n",
    "            gradient = (1 / batch_size) * np.dot(x_batch.T, y_pred - y_batch)\n",
    "            gradient = np.clip(gradient, -gradient_threshold, gradient_threshold)\n",
    "            theta = theta - learning_rate * gradient\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00000005\n",
    "iterations = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model(x, y, learning_rate, iterations, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned theta: [[1.01787854e-03]\n",
      " [8.50831095e-04]\n",
      " [1.06886752e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned theta:\", theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value corresponds to the coefficient for the total_sec_taken feature.\n",
    "\n",
    "The second value corresponds to the coefficient for the has_teacher_cnt feature.\n",
    "\n",
    "The third value corresponds to the coefficient for the points feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.27765737238332305\n",
      "MSE: 0.12483867749192065\n",
      "R-squared: -2.0351630257924342\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.dot(X_test, theta)  \n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE represents the average absolute error between the model's predictions and the actual values. Lower MAE values indicate better performance, and 0 would mean a perfect match.\n",
    "\n",
    "MSE measures the average squared difference between predictions and actual values. Like MAE, lower MSE values indicate better performance. MSE is more sensitive to outliers than MAE.\n",
    "\n",
    "R-squared (R²) is a measure of how well the model explains the variance in the data. An R² value close to 1 indicates that the model is a good fit for the data, while a value close to 0 suggests that the model is no better than predicting the mean of the target variable. A negative R² indicates that the model is performing worse than a horizontal line (predicting the mean) which is the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLYNOMIAL REGRESSION :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.16570360778291787\n",
      "MSE: 0.03916904946960977\n",
      "R-squared: 0.04818024941517707\n"
     ]
    }
   ],
   "source": [
    "degree = 2  \n",
    "\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred = poly_reg.predict(X_test_poly)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AAA: 0.5149770301407934\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[5, 0, 1200000]])\n",
    "\n",
    "new_data_poly = poly.transform(new_data)  \n",
    "\n",
    "# Make predictions for the new AAA\n",
    "new_AAA_prediction = poly_reg.predict(new_data_poly) \n",
    "\n",
    "print(\"Predicted AAA:\", new_AAA_prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
